## PySpark 


### Spark SQL

**DataFrame**: 用来封装分布式数据集。

**RDD**: RDD是一种抽象，是Spark对于分布式数据集的抽象，它用于囊括所有内存中和磁盘中的分布式数据实体。
- partitions: 数据分片
- partitioner: 分片切割规则
- 
